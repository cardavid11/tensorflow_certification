{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdv6CCZQw5Kmjwk4I1fvE5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cardavid11/tensorflow_certification/blob/main/100%20problems/Problem_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This problem will focus on building and training a basic neural network using TensorFlow. Here's your task:\n",
        "\n",
        "### Problem 2: Basic Neural Network with TensorFlow\n",
        "\n",
        "#### Task Description:\n",
        "Create a simple neural network using TensorFlow to classify handwritten digits from the MNIST dataset.\n",
        "\n",
        "1. **Load Data**: Load the MNIST dataset.\n",
        "2. **Preprocess Data**: Normalize the images.\n",
        "3. **Build the Neural Network**:\n",
        "   - Create a model with at least one hidden layer.\n",
        "   - Use appropriate activation functions.\n",
        "4. **Compile the Model**:\n",
        "   - Choose an optimizer, loss function, and metrics.\n",
        "5. **Train the Model**: Train the model on the training data.\n",
        "6. **Evaluate the Model**: Evaluate the model's performance on the test set.\n",
        "7. **Experiment and Optimize**: Try different network architectures, activation functions, or optimizers to improve accuracy.\n",
        "\n",
        "#### Skills Tested:\n",
        "- Understanding of neural network architecture.\n",
        "- Familiarity with TensorFlow's high-level Keras API for model building.\n",
        "- Ability to preprocess data, compile, train, and evaluate models.\n",
        "\n",
        "#### Tips:\n",
        "- Start with a simple architecture and gradually increase complexity if needed.\n",
        "- Pay attention to the model's accuracy and loss during training to identify potential issues like overfitting or underfitting."
      ],
      "metadata": {
        "id": "ytMVtLy-LCio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tensorFlow\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "h9bdv6I5MAWF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data: Load the MNIST dataset.\n",
        "mnist = tf.keras.datasets.mnist"
      ],
      "metadata": {
        "id": "31CzascxM0Zi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Data: Normalize the images.\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# x_train[0].shape\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0 # We normalize the train_images and test_images parts. The original pixel values range from 0 to 255. So we divide them by 255 to put them in the range 0.0 to 1.0."
      ],
      "metadata": {
        "id": "Q188LrWJN80Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total data in x_train\n",
        "x_train.shape\n",
        "# Reserve 10,000 samples for validation\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]"
      ],
      "metadata": {
        "id": "kb0n7b4Jmt7g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Neural Network: Create a model with at least one hidden layer. Use appropriate activation functions.\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "sF4UoGpXN-WH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the Model:Choose an optimizer, loss function, and metrics.\n",
        "model.compile(optimizer='RMSProp', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vGL1BaEePnpq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model: Train the model on the training data.\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          epochs=10,\n",
        "          # We pass some validation for\n",
        "          # monitoring validation loss and metrics\n",
        "          # at the end of each epoch\n",
        "          validation_data=(x_val, y_val)\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkMwka7QQb25",
        "outputId": "345c8226-3e3a-4171-984e-03b69ee1f8d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 0.2759 - accuracy: 0.9220 - val_loss: 0.1553 - val_accuracy: 0.9549\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1307 - accuracy: 0.9617 - val_loss: 0.1242 - val_accuracy: 0.9654\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0945 - accuracy: 0.9722 - val_loss: 0.1012 - val_accuracy: 0.9735\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0747 - accuracy: 0.9786 - val_loss: 0.0955 - val_accuracy: 0.9751\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0628 - accuracy: 0.9817 - val_loss: 0.1028 - val_accuracy: 0.9735\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0522 - accuracy: 0.9845 - val_loss: 0.0950 - val_accuracy: 0.9744\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0441 - accuracy: 0.9873 - val_loss: 0.1053 - val_accuracy: 0.9719\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0373 - accuracy: 0.9889 - val_loss: 0.0987 - val_accuracy: 0.9763\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0321 - accuracy: 0.9907 - val_loss: 0.1042 - val_accuracy: 0.9754\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0286 - accuracy: 0.9919 - val_loss: 0.1014 - val_accuracy: 0.9762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d4a3ee5f640>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model: Evaluate the model's performance on the test set.\n",
        "model_loss, model_accuracy= model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8KZhVjcQdO-",
        "outputId": "2ca50238-7ce1-46f6-d3f2-400d045f67d4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment and Optimize: Try different network architectures, activation functions, or optimizers to improve accuracy.\n",
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model_2.compile(optimizer='RMSProp', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_2.fit(x_train,\n",
        "            y_train,\n",
        "            epochs=32,\n",
        "            # We pass some validation for\n",
        "            # monitoring validation loss and metrics\n",
        "            # at the end of each epoch\n",
        "            validation_data=(x_val, y_val)\n",
        "            )\n",
        "\n",
        "model_2_loss, model_2_accuracy= model_2.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLu8zBhpixI8",
        "outputId": "2ff8adf4-f6eb-4046-870c-830b567c5919"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2515 - accuracy: 0.9251 - val_loss: 0.1461 - val_accuracy: 0.9585\n",
            "Epoch 2/32\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1096 - accuracy: 0.9673 - val_loss: 0.0996 - val_accuracy: 0.9702\n",
            "Epoch 3/32\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0783 - accuracy: 0.9768 - val_loss: 0.0914 - val_accuracy: 0.9765\n",
            "Epoch 4/32\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0623 - accuracy: 0.9818 - val_loss: 0.1024 - val_accuracy: 0.9743\n",
            "Epoch 5/32\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0501 - accuracy: 0.9850 - val_loss: 0.1035 - val_accuracy: 0.9766\n",
            "Epoch 6/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0430 - accuracy: 0.9877 - val_loss: 0.1065 - val_accuracy: 0.9763\n",
            "Epoch 7/32\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0354 - accuracy: 0.9894 - val_loss: 0.1173 - val_accuracy: 0.9743\n",
            "Epoch 8/32\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0302 - accuracy: 0.9916 - val_loss: 0.1240 - val_accuracy: 0.9770\n",
            "Epoch 9/32\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0249 - accuracy: 0.9930 - val_loss: 0.1171 - val_accuracy: 0.9794\n",
            "Epoch 10/32\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0221 - accuracy: 0.9939 - val_loss: 0.1305 - val_accuracy: 0.9769\n",
            "Epoch 11/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0197 - accuracy: 0.9943 - val_loss: 0.1366 - val_accuracy: 0.9783\n",
            "Epoch 12/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0164 - accuracy: 0.9954 - val_loss: 0.1629 - val_accuracy: 0.9742\n",
            "Epoch 13/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.1467 - val_accuracy: 0.9784\n",
            "Epoch 14/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.1692 - val_accuracy: 0.9788\n",
            "Epoch 15/32\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0107 - accuracy: 0.9968 - val_loss: 0.1653 - val_accuracy: 0.9768\n",
            "Epoch 16/32\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1888 - val_accuracy: 0.9766\n",
            "Epoch 17/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.1882 - val_accuracy: 0.9789\n",
            "Epoch 18/32\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1725 - val_accuracy: 0.9786\n",
            "Epoch 19/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.2016 - val_accuracy: 0.9770\n",
            "Epoch 20/32\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.1838 - val_accuracy: 0.9800\n",
            "Epoch 21/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.2096 - val_accuracy: 0.9787\n",
            "Epoch 22/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.2074 - val_accuracy: 0.9770\n",
            "Epoch 23/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.2335 - val_accuracy: 0.9763\n",
            "Epoch 24/32\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.2264 - val_accuracy: 0.9756\n",
            "Epoch 25/32\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.2263 - val_accuracy: 0.9777\n",
            "Epoch 26/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.2178 - val_accuracy: 0.9789\n",
            "Epoch 27/32\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.2286 - val_accuracy: 0.9786\n",
            "Epoch 28/32\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 5.1406e-04 - accuracy: 0.9998 - val_loss: 0.2307 - val_accuracy: 0.9774\n",
            "Epoch 29/32\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 9.6287e-04 - accuracy: 0.9997 - val_loss: 0.2327 - val_accuracy: 0.9788\n",
            "Epoch 30/32\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 5.2075e-04 - accuracy: 0.9998 - val_loss: 0.2341 - val_accuracy: 0.9796\n",
            "Epoch 31/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1808e-04 - accuracy: 1.0000 - val_loss: 0.2310 - val_accuracy: 0.9794\n",
            "Epoch 32/32\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 4.9842e-05 - accuracy: 1.0000 - val_loss: 0.2321 - val_accuracy: 0.9785\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.9815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting:\n",
        "\n",
        "If your model performs significantly better on the training data compared to the validation data, it is likely overfitting.\n",
        "Indicators include a low training loss but a high validation loss, or high training accuracy but lower validation accuracy.\n",
        "\n",
        "Underfitting:\n",
        "\n",
        "If your model performs poorly on both training and validation data, it could be underfitting.\n",
        "This might be indicated by high loss and low accuracy on both training and validation sets."
      ],
      "metadata": {
        "id": "hB2li8Flp5Vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some observations regarding overfitting:\n",
        "\n",
        "1. **Training Loss and Accuracy**:\n",
        "   - Your model achieved a training loss of approximately 4.98e-05 and an accuracy of 100%. These are excellent results, indicating that the model has learned the training dataset very well.\n",
        "\n",
        "2. **Validation Loss and Accuracy**:\n",
        "   - The validation loss is 0.2321, which is significantly higher than the training loss.\n",
        "   - The validation accuracy is 97.85%, which is high but noticeably lower than the training accuracy.\n",
        "\n",
        "### Analysis\n",
        "\n",
        "- **Signs of Overfitting**:\n",
        "  - The substantial difference between training and validation loss suggests that the model might be overfitting. This means that while it performs exceptionally well on the training data, it is not as effective on unseen data (validation set).\n",
        "  - The perfect training accuracy (100%) compared to a lower validation accuracy reinforces this indication of overfitting.\n",
        "\n",
        "### Recommendations\n",
        "\n",
        "1. **Data Augmentation**: If you haven't already, consider using data augmentation to introduce more variability into your training data, making your model more robust.\n",
        "\n",
        "2. **Regularization**: Implement regularization techniques such as dropout or L1/L2 regularization to prevent the model from becoming too fitted to the training data.\n",
        "\n",
        "3. **Model Complexity**: Consider simplifying your model. Sometimes, a less complex model can generalize better.\n",
        "\n",
        "4. **Early Stopping**: Implement early stopping during training. This technique stops training when the validation loss stops decreasing, preventing overfitting.\n",
        "\n",
        "5. **Cross-validation**: Use cross-validation to ensure that the model's performance is consistent across different subsets of the data.\n",
        "\n",
        "By addressing these points, you can improve your model's ability to generalize and reduce the risk of overfitting."
      ],
      "metadata": {
        "id": "niuumDeUqhFW"
      }
    }
  ]
}